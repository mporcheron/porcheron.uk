---
seo_description: "TODO"
---

# Designing inclusive voice interfaces

The 'hands-free' and 'eyes-free' nature of voice/speech interfaces allows for their use in a wide variety of settings and for myriad purposes, from routine tasks such as setting times while cooking through to sending text messages while driving a car. As anyone who has used any voice interface will know, things don't always go as swimmingly as promised in promotional materials (such as the [the original Amazon Echo promotional video](https://www.youtube.com/watch?v=CYtb8RRj5r4 "Introducing Amazon Echo on YouTube") or the [Google Duplex initial demonstration](https://www.youtube.com/watch?v=D5VN56jQMWM "'Google Duplex: A.I. Assistant Calls Local Businesses To Make Appointments' on YouTube")). This is nothing unique to voice interfaces---all technologies go wrong sometimes and a key component of the user experience is how to enable _error recovery_.  

With voice interfaces, some common problems people face are caused by sporadic events (e.g., someone coughing during an utterance), or technical (e.g., an Internet connection dropping out), and can't necessarily be easily avoided. However, there are also a staggering plethora of _sociotechnical_ issues that have are worthy of exploration, that _can_ be addressed in design, but are relatively understudied. Over the past couple of years, through a number of collaborations, I've been working to understand how we can refine the design of voice technologies to take into sociotechnical factors including peoples' speech disfluencies such as stammering/stuttering, whether the users are second-language speakers, or even if the users are in fact children or young adults.

<!--more-->

Blah

{% include associated_pubs.html pubs='Exploring Smart Speaker User Experience for People Who Stammer||Comparing Command Construction in Native and Non-Native Speaker IPA Interaction through Conversation Analysis||The Last Decade of HCI Research on Children and Voice-based Conversational Agents' %}

----

## References